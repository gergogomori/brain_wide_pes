{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1911YZOumNcLaHXcB15nqhy7oVQx08vj7",
      "authorship_tag": "ABX9TyNiWz2sE+SnEJ5M1UjgiFoJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gergogomori/brain_wide_pes/blob/main/pes_demixing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ONE-api\n",
        "!pip install iblatlas\n",
        "!pip install ibllib\n"
      ],
      "metadata": {
        "id": "KD-N2wA4WQnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwQJeWfE8ReE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import permutation_test\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "from one.api import ONE\n",
        "one = ONE(base_url='https://openalyx.internationalbrainlab.org', password='international', silent=True)\n",
        "\n",
        "eids = one.search(datasets='spikes.times.npy')\n",
        "print(len(eids))\n",
        "\n",
        "from iblatlas.atlas import AllenAtlas\n",
        "from iblatlas.plots import plot_swanson_vector\n",
        "brain_atlas   = AllenAtlas()\n",
        "brain_regions = brain_atlas.regions\n",
        "\n",
        "from brainbox.io.one import SpikeSortingLoader\n",
        "\n",
        "import warnings\n",
        "import one.alf.exceptions as alferr\n",
        "warnings.filterwarnings(\"ignore\", category=alferr.ALFWarning)\n",
        "\n",
        "import uuid\n",
        "\n",
        "import pandas  as pd\n",
        "import seaborn as sns\n",
        "\n",
        "contrasts = np.array([0.0625, 0.125, 0.25, 1.0])\n",
        "\n",
        "rng = np.random.default_rng()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "\n",
        "mpl.rcParams.update({\n",
        "    'axes.labelsize'  : 15,\n",
        "    'xtick.labelsize' : 14,\n",
        "    'ytick.labelsize' : 14,\n",
        "    'legend.fontsize' : 14})\n"
      ],
      "metadata": {
        "id": "8aOmHsn8ThCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading external data"
      ],
      "metadata": {
        "id": "oAHedr8-9fSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('*** Update the folder path here to match your directory structure ***', 'rb') as f:\n",
        "    trials_all = pickle.load(f)\n",
        "\n",
        "with open('*** Update the folder path here to match your directory structure ***', 'rb') as f:\n",
        "    fr_all = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "LyfaHh_d89yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTED PARAMETERS\n",
        "\n",
        "min_n_trials_neuro = 10\n",
        "\n",
        "t_lims     = (-350.0, 350.0) # ms\n",
        "sampl_rate = 10.0 # ms\n",
        "time_axis  = np.arange(t_lims[0] + sampl_rate / 2, t_lims[1] - sampl_rate / 2 + 1, sampl_rate)\n",
        "\n",
        "print(time_axis)\n"
      ],
      "metadata": {
        "id": "6XjwXkHJ890u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW PARAMETERS\n",
        "\n",
        "min_n_trials    = 8\n",
        "time_end_perc   = 5\n",
        "pes_rt_perc     = 55\n",
        "min_fr_std      = 0.1\n",
        "min_pens_trials = 5\n",
        "time_eps        = 5.0 # ms\n",
        "time_perc_plot  = 80\n",
        "perc_coeff      = 80\n",
        "signif_lvl      = 0.05\n",
        "n_char_eid      = 4\n"
      ],
      "metadata": {
        "id": "T1Es5v5YPJTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorizing trials within sessions"
      ],
      "metadata": {
        "id": "kvrQQVUG_tsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matched_trials = {}\n",
        "\n",
        "for curr_eid_contr in sorted(list(fr_all.keys())):\n",
        "\n",
        "    act_EID, act_contr = curr_eid_contr\n",
        "\n",
        "    act_trials = sorted(list(trials_all[act_EID][act_contr].keys()))\n",
        "\n",
        "    curr_RTs_pcorr = []\n",
        "\n",
        "    for trial in act_trials:\n",
        "\n",
        "        if trials_all[act_EID][act_contr][trial][3] == -1:\n",
        "            curr_RTs_pcorr.append(trials_all[act_EID][act_contr][trial][0])\n",
        "\n",
        "    curr_pes_thres = np.percentile(curr_RTs_pcorr, pes_rt_perc)\n",
        "\n",
        "    curr_pes_trials_left   = []\n",
        "    curr_pens_trials_left  = []\n",
        "    curr_pcorr_trials_left = []\n",
        "\n",
        "    curr_pes_trials_right   = []\n",
        "    curr_pens_trials_right  = []\n",
        "    curr_pcorr_trials_right = []\n",
        "\n",
        "    for trial in act_trials:\n",
        "\n",
        "        if (trials_all[act_EID][act_contr][trial][3] == 1) and (trials_all[act_EID][act_contr][trial][0] >= curr_pes_thres):\n",
        "\n",
        "            if trials_all[act_EID][act_contr][trial][1] == -1:\n",
        "                curr_pes_trials_left.append(trial)\n",
        "\n",
        "            else:\n",
        "                assert(trials_all[act_EID][act_contr][trial][1] == 1)\n",
        "                curr_pes_trials_right.append(trial)\n",
        "\n",
        "        elif (trials_all[act_EID][act_contr][trial][3] == 1) and (trials_all[act_EID][act_contr][trial][0] < curr_pes_thres):\n",
        "\n",
        "            if trials_all[act_EID][act_contr][trial][1] == -1:\n",
        "                curr_pens_trials_left.append(trial)\n",
        "\n",
        "            else:\n",
        "                assert(trials_all[act_EID][act_contr][trial][1] == 1)\n",
        "                curr_pens_trials_right.append(trial)\n",
        "\n",
        "\n",
        "        elif trials_all[act_EID][act_contr][trial][3] == -1:\n",
        "\n",
        "            if trials_all[act_EID][act_contr][trial][1] == -1:\n",
        "                curr_pcorr_trials_left.append(trial)\n",
        "\n",
        "            else:\n",
        "                assert(trials_all[act_EID][act_contr][trial][1] == 1)\n",
        "                curr_pcorr_trials_right.append(trial)\n",
        "\n",
        "    assert(len(set(curr_pes_trials_left))    == len(curr_pes_trials_left))\n",
        "    assert(len(set(curr_pens_trials_left))   == len(curr_pens_trials_left))\n",
        "    assert(len(set(curr_pcorr_trials_left))  == len(curr_pcorr_trials_left))\n",
        "\n",
        "    assert(len(set(curr_pes_trials_right))   == len(curr_pes_trials_right))\n",
        "    assert(len(set(curr_pens_trials_right))  == len(curr_pens_trials_right))\n",
        "    assert(len(set(curr_pcorr_trials_right)) == len(curr_pcorr_trials_right))\n",
        "\n",
        "    assert(len(set(curr_pes_trials_left)   &\n",
        "               set(curr_pens_trials_left)  &\n",
        "               set(curr_pcorr_trials_left) &\n",
        "               set(curr_pes_trials_right)  &\n",
        "               set(curr_pens_trials_right) &\n",
        "               set(curr_pcorr_trials_right)) == 0)\n",
        "\n",
        "    if ((len(curr_pes_trials_left) >= min_n_trials) and (len(curr_pens_trials_left) >= min_pens_trials)):\n",
        "\n",
        "        matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')] = {'error' : {'pes'  : curr_pes_trials_left,\n",
        "                                                                                     'npes' : curr_pens_trials_left}}\n",
        "\n",
        "    if ((len(curr_pes_trials_right) >= min_n_trials) and (len(curr_pens_trials_right) >= min_pens_trials)):\n",
        "\n",
        "        matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')] = {'error' : {'pes'  : curr_pes_trials_right,\n",
        "                                                                                      'npes' : curr_pens_trials_right}}\n",
        "\n",
        "    if (len(curr_pes_trials_left) >= min_n_trials) and (len(curr_pcorr_trials_left) >= len(curr_pes_trials_left)):\n",
        "\n",
        "        if (curr_eid_contr[0], curr_eid_contr[1], 'left') not in matched_trials.keys():\n",
        "            matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')] = {'choice' : {'pes' : curr_pes_trials_left}}\n",
        "        else:\n",
        "            matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['choice'] = {'pes' : curr_pes_trials_left}\n",
        "\n",
        "        curr_pes_rts   = [trials_all[act_EID][act_contr][trial][0] for trial in curr_pes_trials_left]\n",
        "        curr_pcorr_rts = [(trial, trials_all[act_EID][act_contr][trial][0]) for trial in curr_pcorr_trials_left]\n",
        "\n",
        "        curr_matched_pcorr     = []\n",
        "        curr_matched_pcorr_rts = []\n",
        "\n",
        "        # Match post-correct trials to PES\n",
        "\n",
        "        for curr_RT in curr_pes_rts:\n",
        "\n",
        "            curr_match = curr_pcorr_rts[np.argmin(np.abs(curr_RT - np.array([pair[1] for pair in curr_pcorr_rts]))).astype(int)]\n",
        "\n",
        "            curr_pcorr_rts.remove(curr_match)\n",
        "\n",
        "            curr_matched_pcorr.append(curr_match[0])\n",
        "            curr_matched_pcorr_rts.append(curr_match[1])\n",
        "\n",
        "        matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['choice']['npes'] = sorted(curr_matched_pcorr)\n",
        "\n",
        "        assert(len(set(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['choice']['pes']) &\n",
        "                   set(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['choice']['npes'])) == 0)\n",
        "\n",
        "        assert(len(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['choice']['pes']) ==\n",
        "               len(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['choice']['npes']))\n",
        "\n",
        "    if (len(curr_pes_trials_right) >= min_n_trials) and (len(curr_pcorr_trials_right) >= len(curr_pes_trials_right)):\n",
        "\n",
        "        if (curr_eid_contr[0], curr_eid_contr[1], 'right') not in matched_trials.keys():\n",
        "            matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')] = {'choice' : {'pes' : curr_pes_trials_right}}\n",
        "        else:\n",
        "            matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['choice'] = {'pes' : curr_pes_trials_right}\n",
        "\n",
        "        curr_pes_rts   = [trials_all[act_EID][act_contr][trial][0] for trial in curr_pes_trials_right]\n",
        "        curr_pcorr_rts = [(trial, trials_all[act_EID][act_contr][trial][0]) for trial in curr_pcorr_trials_right]\n",
        "\n",
        "        curr_matched_pcorr     = []\n",
        "        curr_matched_pcorr_rts = []\n",
        "\n",
        "        # Match post-correct trials to PES\n",
        "\n",
        "        for curr_RT in curr_pes_rts:\n",
        "\n",
        "            curr_match = curr_pcorr_rts[np.argmin(np.abs(curr_RT - np.array([pair[1] for pair in curr_pcorr_rts]))).astype(int)]\n",
        "\n",
        "            curr_pcorr_rts.remove(curr_match)\n",
        "\n",
        "            curr_matched_pcorr.append(curr_match[0])\n",
        "            curr_matched_pcorr_rts.append(curr_match[1])\n",
        "\n",
        "        matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['choice']['npes'] = sorted(curr_matched_pcorr)\n",
        "\n",
        "        assert(len(set(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['choice']['pes']) &\n",
        "                   set(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['choice']['npes'])) == 0)\n",
        "\n",
        "        assert(len(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['choice']['pes']) ==\n",
        "               len(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['choice']['npes']))\n",
        "\n",
        "    if (curr_eid_contr[0], curr_eid_contr[1], 'left') in matched_trials.keys():\n",
        "\n",
        "        if (('error'  in matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')].keys()) and\n",
        "            ('choice' in matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')].keys())):\n",
        "\n",
        "            assert(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['error']['pes'] ==\n",
        "                   matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['choice']['pes'])\n",
        "\n",
        "            assert(len(set(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['error']['npes']) &\n",
        "                       set(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'left')]['choice']['npes'])) == 0)\n",
        "\n",
        "    if (curr_eid_contr[0], curr_eid_contr[1], 'right') in matched_trials.keys():\n",
        "\n",
        "        if (('error'  in matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')].keys()) and\n",
        "            ('choice' in matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')].keys())):\n",
        "\n",
        "            assert(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['error']['pes'] ==\n",
        "                   matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['choice']['pes'])\n",
        "\n",
        "            assert(len(set(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['error']['npes']) &\n",
        "                       set(matched_trials[(curr_eid_contr[0], curr_eid_contr[1], 'right')]['choice']['npes'])) == 0)\n",
        "\n",
        "print(f\"Total number of ERROR tests: {len([sess_contr_side  for sess_contr_side in list(matched_trials.keys()) if 'error'  in list(matched_trials[sess_contr_side].keys())])}\")\n",
        "print(f\"Total number of CHOICE tests: {len([sess_contr_side for sess_contr_side in list(matched_trials.keys()) if 'choice' in list(matched_trials[sess_contr_side].keys())])}\")\n",
        "\n",
        "with open('*** Update the folder path here to match your directory structure ***', 'wb') as f:\n",
        "    pickle.dump(matched_trials, f, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "S5y6vZVL9uE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verification\n",
        "\n",
        "rand_eid_contr_side = random.choice(list(matched_trials.keys()))\n",
        "\n",
        "if 'error' in matched_trials[rand_eid_contr_side].keys():\n",
        "\n",
        "    rand_pes_rts  = []\n",
        "    rand_npes_rts = []\n",
        "\n",
        "    for trial in matched_trials[rand_eid_contr_side]['error']['pes']:\n",
        "\n",
        "        if rand_eid_contr_side[2] == 'left':\n",
        "            assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][1] == -1)\n",
        "        else:\n",
        "            assert(rand_eid_contr_side[2] == 'right')\n",
        "            assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][1] == 1)\n",
        "\n",
        "        assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][3] == 1)\n",
        "\n",
        "        rand_pes_rts.append(int(np.round(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][0])))\n",
        "\n",
        "    for trial in matched_trials[rand_eid_contr_side]['error']['npes']:\n",
        "\n",
        "        if rand_eid_contr_side[2] == 'left':\n",
        "            assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][1] == -1)\n",
        "        else:\n",
        "            assert(rand_eid_contr_side[2] == 'right')\n",
        "            assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][1] == 1)\n",
        "\n",
        "        assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][3] == 1)\n",
        "\n",
        "        rand_npes_rts.append(int(np.round(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][0])))\n",
        "\n",
        "    assert(np.mean(rand_pes_rts) > np.mean(rand_npes_rts))\n",
        "\n",
        "    print('Error trial sets are correct.')\n",
        "\n",
        "\n",
        "if 'choice' in matched_trials[rand_eid_contr_side].keys():\n",
        "\n",
        "    rand_pes_rts  = []\n",
        "    rand_npes_rts = []\n",
        "\n",
        "    for trial in matched_trials[rand_eid_contr_side]['choice']['pes']:\n",
        "\n",
        "        if rand_eid_contr_side[2] == 'left':\n",
        "            assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][1] == -1)\n",
        "        else:\n",
        "            assert(rand_eid_contr_side[2] == 'right')\n",
        "            assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][1] == 1)\n",
        "\n",
        "        assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][3] == 1)\n",
        "\n",
        "        rand_pes_rts.append(int(np.round(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][0])))\n",
        "\n",
        "    for trial in matched_trials[rand_eid_contr_side]['choice']['npes']:\n",
        "\n",
        "        if rand_eid_contr_side[2] == 'left':\n",
        "            assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][1] == -1)\n",
        "        else:\n",
        "            assert(rand_eid_contr_side[2] == 'right')\n",
        "            assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][1] == 1)\n",
        "\n",
        "        assert(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][3] == -1)\n",
        "\n",
        "        rand_npes_rts.append(int(np.round(trials_all[rand_eid_contr_side[0]][rand_eid_contr_side[1]][trial][0])))\n",
        "\n",
        "    print(sorted(rand_pes_rts),  'ms')\n",
        "    print(sorted(rand_npes_rts), 'ms')\n"
      ],
      "metadata": {
        "id": "Aq71Q6BIsO6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_triplets = list(set(matched_trials.keys()))\n",
        "\n",
        "print(f'Total number of triplets: {len(all_triplets)}')\n"
      ],
      "metadata": {
        "id": "EuYhGyYHyN78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overview_triplets = {}\n",
        "\n",
        "for sess_contr_side in sorted(list(matched_trials.keys())):\n",
        "\n",
        "    for test_case in sorted(list(matched_trials[sess_contr_side].keys())):\n",
        "\n",
        "        if sess_contr_side not in overview_triplets.keys():\n",
        "            overview_triplets[sess_contr_side] = {}\n",
        "\n",
        "        overview_triplets[sess_contr_side][test_case] = {}\n",
        "\n",
        "        overview_triplets[sess_contr_side][test_case]['pes']  = matched_trials[sess_contr_side][test_case]['pes']\n",
        "        overview_triplets[sess_contr_side][test_case]['npes'] = matched_trials[sess_contr_side][test_case]['npes']\n",
        "\n",
        "assert(len(list(overview_triplets.keys())) == len(list(set(overview_triplets.keys()))))\n",
        "\n",
        "table_triplets = {sess_contr_side : {} for sess_contr_side in sorted(list(overview_triplets.keys()))}\n",
        "\n",
        "for sess_contr_side in sorted(list(overview_triplets.keys())):\n",
        "\n",
        "    if ('error' in overview_triplets[sess_contr_side].keys()) and ('choice' in overview_triplets[sess_contr_side].keys()):\n",
        "\n",
        "        assert(overview_triplets[sess_contr_side]['error']['pes'] == overview_triplets[sess_contr_side]['choice']['pes'])\n",
        "\n",
        "        table_triplets[sess_contr_side]['pes']   = len(overview_triplets[sess_contr_side]['error']['pes'])\n",
        "        table_triplets[sess_contr_side]['nslow'] = len(overview_triplets[sess_contr_side]['error']['npes'])\n",
        "        table_triplets[sess_contr_side]['corr']  = len(overview_triplets[sess_contr_side]['choice']['npes'])\n",
        "\n",
        "    elif ('choice' in overview_triplets[sess_contr_side].keys()):\n",
        "        table_triplets[sess_contr_side]['pes']   = len(overview_triplets[sess_contr_side]['choice']['pes'])\n",
        "        table_triplets[sess_contr_side]['nslow'] = 'insufficient'\n",
        "        table_triplets[sess_contr_side]['corr']  = len(overview_triplets[sess_contr_side]['choice']['npes'])\n",
        "\n",
        "    else:\n",
        "        print('There is triplet with only error test!')\n",
        "\n",
        "assert(len(list(overview_triplets.keys())) == len(list(table_triplets.keys())))\n",
        "\n",
        "triplets_sorted = sorted(table_triplets, key=lambda k : table_triplets[k]['pes'], reverse=True)\n"
      ],
      "metadata": {
        "id": "DU5MJzBJ0W3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_table_trials = pd.DataFrame({\n",
        "    'Triplet'      : [str(str(sess_contr_side[0])[ : n_char_eid] + ', ' + str(sess_contr_side[1]) + ', ' + sess_contr_side[2])  for sess_contr_side in triplets_sorted],\n",
        "    'Slow post-error'     : [table_triplets[sess_contr_side]['pes']   for sess_contr_side in triplets_sorted],\n",
        "    'Non-slow post-error' : [table_triplets[sess_contr_side]['nslow'] for sess_contr_side in triplets_sorted],\n",
        "    'Slow post-correct'   : [table_triplets[sess_contr_side]['corr']  for sess_contr_side in triplets_sorted]})\n",
        "\n",
        "\n",
        "plt.table(cellText=df_table_trials.values, colLabels=df_table_trials.columns, cellLoc='center', loc='center')\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', bbox_inches='tight', dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8e2E_M3Z0rS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating coefficients for all neurons"
      ],
      "metadata": {
        "id": "v9zE2l8Z9pZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeff_axes = {}\n",
        "fr_z       = {}\n",
        "\n",
        "eids_contrs = []\n",
        "\n",
        "for curr_eid_contr_side in sorted(list(matched_trials.keys())):\n",
        "    if (curr_eid_contr_side[0], curr_eid_contr_side[1]) not in eids_contrs:\n",
        "        eids_contrs.append((curr_eid_contr_side[0], curr_eid_contr_side[1]))\n",
        "\n",
        "for ind_eid_contr, curr_eid_contr in enumerate(eids_contrs):\n",
        "\n",
        "    print('Done with', np.around(ind_eid_contr / len(eids_contrs) * 100, 1), '% of the data.')\n",
        "\n",
        "    EID, contr  = curr_eid_contr\n",
        "    curr_trials = sorted(list(trials_all[EID][contr].keys()))\n",
        "\n",
        "    n_left_pc  = 0\n",
        "    n_right_pc = 0\n",
        "    n_left_pe  = 0\n",
        "    n_right_pe = 0\n",
        "\n",
        "    ind2trials     = {}\n",
        "    curr_trial_ind = 0\n",
        "\n",
        "    for ind_trial, trial in enumerate(curr_trials):\n",
        "\n",
        "        ind2trials[curr_trial_ind] = trial\n",
        "        curr_trial_ind += 1\n",
        "\n",
        "        if trials_all[EID][contr][trial][1]   == -1 and trials_all[EID][contr][trial][3] == -1:\n",
        "            n_left_pc  += 1\n",
        "        elif trials_all[EID][contr][trial][1] ==  1 and trials_all[EID][contr][trial][3] == -1:\n",
        "            n_right_pc += 1\n",
        "        elif trials_all[EID][contr][trial][1] == -1 and trials_all[EID][contr][trial][3] ==  1:\n",
        "            n_left_pe  += 1\n",
        "        elif trials_all[EID][contr][trial][1] ==  1 and trials_all[EID][contr][trial][3] ==  1:\n",
        "            n_right_pe += 1\n",
        "\n",
        "    assert(n_left_pc >= min_n_trials_neuro and n_right_pc >= min_n_trials_neuro and n_left_pe >= min_n_trials_neuro and n_right_pe >= min_n_trials_neuro)\n",
        "\n",
        "    curr_data = []\n",
        "\n",
        "    for trial in curr_trials:\n",
        "        curr_data.append([trials_all[EID][contr][trial][1], trials_all[EID][contr][trial][3]])\n",
        "\n",
        "    curr_X = np.array(curr_data)\n",
        "\n",
        "    curr_neurons = sorted(list(fr_all[curr_eid_contr].keys()))\n",
        "\n",
        "    for neuron in curr_neurons:\n",
        "\n",
        "        assert(sorted(list(fr_all[curr_eid_contr][neuron].keys())) == curr_trials)\n",
        "\n",
        "        curr_Y = []\n",
        "\n",
        "        for trial in curr_trials:\n",
        "            curr_Y.append(fr_all[curr_eid_contr][neuron][trial])\n",
        "\n",
        "        if np.std(curr_Y) > min_fr_std:\n",
        "\n",
        "            if ((curr_eid_contr not in sorted(list(coeff_axes.keys()))) and\n",
        "                (curr_eid_contr not in sorted(list(fr_z.keys())))):\n",
        "                coeff_axes[curr_eid_contr] = {}\n",
        "                fr_z[curr_eid_contr]       = {}\n",
        "\n",
        "            if neuron not in sorted(list(fr_z[curr_eid_contr].keys())):\n",
        "                fr_z[curr_eid_contr][neuron] = {}\n",
        "\n",
        "            curr_Y = (np.array(curr_Y) - np.mean(curr_Y)) / np.std(curr_Y)\n",
        "\n",
        "            curr_fr_z       = []\n",
        "            curr_coeff_axes = []\n",
        "\n",
        "            for ind_time, time in enumerate(time_axis):\n",
        "\n",
        "                assert(len(curr_X) == len(curr_Y[ : , ind_time]))\n",
        "\n",
        "                curr_model = LinearRegression(fit_intercept=True)\n",
        "                curr_res   = curr_model.fit(curr_X, curr_Y[ : , ind_time])\n",
        "\n",
        "                curr_fr_z.append(curr_Y[ : , ind_time])\n",
        "\n",
        "                curr_coeff_axes.append(np.concatenate((curr_res.coef_, np.array([curr_res.intercept_]))))\n",
        "\n",
        "            curr_fr_z       = np.array(curr_fr_z)\n",
        "            curr_coeff_axes = np.array(curr_coeff_axes)\n",
        "\n",
        "            assert(curr_fr_z.shape       == (len(time_axis), len(curr_trials)))\n",
        "            assert(curr_coeff_axes.shape == (len(time_axis), 3))\n",
        "\n",
        "            for ind_trial in range(len(ind2trials.keys())):\n",
        "\n",
        "                assert(len(curr_fr_z[ : , ind_trial]) == len(time_axis))\n",
        "\n",
        "                fr_z[curr_eid_contr][neuron][ind2trials[ind_trial]] = curr_fr_z[ : , ind_trial]\n",
        "\n",
        "            for ind_feature, feature in enumerate(['choice', 'error', 'unmod']):\n",
        "\n",
        "                assert(len(curr_coeff_axes[ : , ind_feature]) == len(time_axis))\n",
        "\n",
        "                if feature not in coeff_axes[curr_eid_contr].keys():\n",
        "                    coeff_axes[curr_eid_contr][feature] = {neuron : curr_coeff_axes[ : , ind_feature]}\n",
        "                else:\n",
        "                    coeff_axes[curr_eid_contr][feature][neuron] = curr_coeff_axes[ : , ind_feature]\n",
        "\n",
        "    for curr_repr in ['choice', 'error', 'unmod']:\n",
        "\n",
        "        assert(sorted(list(coeff_axes[curr_eid_contr][curr_repr].keys())) == sorted(list(fr_z[curr_eid_contr].keys())))\n",
        "\n",
        "assert(sorted(list(coeff_axes.keys())) == sorted(list(fr_z.keys())))\n",
        "\n",
        "with open('*** Update the folder path here to match your directory structure ***', 'wb') as f:\n",
        "    pickle.dump(fr_z, f, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "ozOtRtKa9xt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Brain regions of each neuron"
      ],
      "metadata": {
        "id": "qfGIDyjIWvg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron_region = {}\n",
        "extracted_eid = []\n",
        "\n",
        "for ind_curr_eid_contr_side, curr_eid_contr_side in enumerate(sorted(list(coeff_axes.keys()))):\n",
        "\n",
        "    print('Done with', np.around(ind_curr_eid_contr_side / len(coeff_axes.keys()) * 100, 1), '% of the data.')\n",
        "\n",
        "    if curr_eid_contr_side[0] not in extracted_eid:\n",
        "\n",
        "        curr_pids_neurons = {}\n",
        "\n",
        "        assert(sorted(list(coeff_axes[(curr_eid_contr_side[0], curr_eid_contr_side[1])]['error'].keys())) ==\n",
        "            sorted(list(coeff_axes[(curr_eid_contr_side[0], curr_eid_contr_side[1])]['choice'].keys())))\n",
        "\n",
        "        for neuron in sorted(list(coeff_axes[(curr_eid_contr_side[0], curr_eid_contr_side[1])]['error'].keys())):\n",
        "\n",
        "            if neuron[0] not in curr_pids_neurons.keys():\n",
        "                curr_pids_neurons[neuron[0]] = [neuron[1]]\n",
        "            else:\n",
        "                curr_pids_neurons[neuron[0]].append(neuron[1])\n",
        "\n",
        "        for PID in sorted(list(curr_pids_neurons.keys())):\n",
        "\n",
        "            sl = SpikeSortingLoader(pid=PID, one=one, atlas=brain_atlas)\n",
        "            spikes, clusters, channels = sl.load_spike_sorting()\n",
        "            clusters = sl.merge_clusters(spikes, clusters, channels)\n",
        "\n",
        "            for clust_num in curr_pids_neurons[PID]:\n",
        "\n",
        "                curr_region = brain_regions.id2acronym(clusters['atlas_id'][np.where(clusters['cluster_id'] == clust_num)[0][0]], mapping='Swanson')[0]\n",
        "\n",
        "                if ((curr_region != 'root')  and\n",
        "                    (curr_region != 'P')     and\n",
        "                    (curr_region != 'HPF')   and\n",
        "                    (curr_region != 'MY')    and\n",
        "                    (curr_region != 'void')  and\n",
        "                    (curr_region != 'PO')    and\n",
        "                    (curr_region != 'HY')    and\n",
        "                    (curr_region != 'POST')  and\n",
        "                    (curr_region != 'CTXsp') and\n",
        "                    (curr_region != 'LA')):\n",
        "\n",
        "                    if ((curr_region == 'VPL')   or\n",
        "                        (curr_region == 'VPLpc') or\n",
        "                        (curr_region == 'VPM')   or\n",
        "                        (curr_region == 'VPMpc')):\n",
        "                        curr_region = 'VP'\n",
        "                    elif ((curr_region == 'SCdg') or\n",
        "                        (curr_region == 'SCdw') or\n",
        "                        (curr_region == 'SCiw') or\n",
        "                        (curr_region == 'SCig')):\n",
        "                        curr_region = 'SCm'\n",
        "                    elif ((curr_region == 'CUL4') or\n",
        "                        (curr_region == 'CUL5') or\n",
        "                        (curr_region == 'CUL4 5')):\n",
        "                        curr_region = 'CUL'\n",
        "                    elif ((curr_region == 'LAV')  or\n",
        "                        (curr_region == 'MV')   or\n",
        "                        (curr_region == 'SPIV') or\n",
        "                        (curr_region == 'SUV')):\n",
        "                        curr_region = 'VNC'\n",
        "                    elif ((curr_region == 'RSPagl')  or\n",
        "                        (curr_region == 'RSPd')   or\n",
        "                        (curr_region == 'RSPv')):\n",
        "                        curr_region = 'RSP'\n",
        "\n",
        "                    neuron_region[(PID, clust_num)] = curr_region\n",
        "\n",
        "        extracted_eid.append(curr_eid_contr_side[0])\n",
        "\n",
        "        shutil.rmtree('/root/Downloads/ONE/openalyx.internationalbrainlab.org/' + one.get_details(curr_eid_contr[0])['lab'], ignore_errors=True)\n",
        "\n",
        "with open('*** Update the folder path here to match your directory structure ***', 'wb') as f:\n",
        "    pickle.dump(neuron_region, f, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "_UBE2lTKsMA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting the weights for each neuron"
      ],
      "metadata": {
        "id": "ZPru624wCEg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_max_coeffs = {}\n",
        "w_max_coeffs = {}\n",
        "\n",
        "for curr_eid_contr in sorted(list(coeff_axes.keys())):\n",
        "\n",
        "    curr_rts = []\n",
        "\n",
        "    for trial in sorted(list(trials_all[curr_eid_contr[0]][curr_eid_contr[1]].keys())):\n",
        "        curr_rts.append(trials_all[curr_eid_contr[0]][curr_eid_contr[1]][trial][0])\n",
        "\n",
        "    curr_time_inds = (int(np.argmin(np.abs(time_axis - (0.0 + time_eps))).astype(int)), int(np.argmin(np.abs(time_axis - np.percentile(curr_rts, time_end_perc))).astype(int)) + 1)\n",
        "\n",
        "    for curr_repr in ['error', 'choice']:\n",
        "\n",
        "        curr_weights = []\n",
        "\n",
        "        for neuron in sorted(list(coeff_axes[curr_eid_contr][curr_repr].keys())):\n",
        "\n",
        "            curr_weights.append(coeff_axes[curr_eid_contr][curr_repr][neuron][curr_time_inds[0] : curr_time_inds[1]])\n",
        "\n",
        "        curr_weights = np.array(curr_weights)\n",
        "\n",
        "        assert(curr_weights.shape == (len(list(coeff_axes[curr_eid_contr][curr_repr].keys())), curr_time_inds[1] - curr_time_inds[0]))\n",
        "\n",
        "        global_ind = curr_time_inds[0] + int(np.argmax(np.linalg.norm(curr_weights, axis=0)).astype(int))\n",
        "\n",
        "        assert(time_axis[global_ind] > 0.0)\n",
        "        assert(time_axis[global_ind] < time_axis[-1])\n",
        "\n",
        "        if ((curr_eid_contr not in t_max_coeffs.keys()) and\n",
        "            (curr_eid_contr not in w_max_coeffs.keys())):\n",
        "\n",
        "            t_max_coeffs[curr_eid_contr] = {curr_repr : global_ind}\n",
        "            w_max_coeffs[curr_eid_contr] = {curr_repr : {}}\n",
        "\n",
        "        else:\n",
        "            t_max_coeffs[curr_eid_contr][curr_repr] = global_ind\n",
        "            w_max_coeffs[curr_eid_contr][curr_repr] = {}\n",
        "\n",
        "        for neuron in sorted(list(coeff_axes[curr_eid_contr][curr_repr].keys())):\n",
        "\n",
        "            assert(len(coeff_axes[curr_eid_contr][curr_repr][neuron]) == len(time_axis))\n",
        "\n",
        "            w_max_coeffs[curr_eid_contr][curr_repr][neuron] = coeff_axes[curr_eid_contr][curr_repr][neuron][global_ind]\n",
        "\n",
        "assert(sorted(list(t_max_coeffs.keys())) == sorted(list(w_max_coeffs.keys())))\n",
        "\n"
      ],
      "metadata": {
        "id": "hCauZpaPWUlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computing the projections"
      ],
      "metadata": {
        "id": "ZjjsXPsMN60F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proj_all = {}\n",
        "\n",
        "for curr_eid_contr_side in sorted(list(matched_trials.keys())):\n",
        "\n",
        "    for curr_repr in sorted(list(matched_trials[curr_eid_contr_side].keys())):\n",
        "\n",
        "        curr_coeffs = []\n",
        "\n",
        "        for neuron in sorted(list(w_max_coeffs[(curr_eid_contr_side[0], curr_eid_contr_side[1])][curr_repr].keys())):\n",
        "            curr_coeffs.append(w_max_coeffs[(curr_eid_contr_side[0], curr_eid_contr_side[1])][curr_repr][neuron])\n",
        "\n",
        "        assert(len(curr_coeffs) == len(list(w_max_coeffs[(curr_eid_contr_side[0], curr_eid_contr_side[1])][curr_repr].keys())))\n",
        "\n",
        "        curr_max_w_len = np.linalg.norm(curr_coeffs)\n",
        "\n",
        "        curr_trials = matched_trials[curr_eid_contr_side][curr_repr]['pes'] + matched_trials[curr_eid_contr_side][curr_repr]['npes']\n",
        "\n",
        "        for trial in sorted(curr_trials):\n",
        "\n",
        "            curr_dot_prod = []\n",
        "\n",
        "            for neuron in sorted(list(fr_z[(curr_eid_contr_side[0], curr_eid_contr_side[1])].keys())):\n",
        "\n",
        "                curr_dot_prod.append(w_max_coeffs[(curr_eid_contr_side[0], curr_eid_contr_side[1])][curr_repr][neuron] * fr_z[(curr_eid_contr_side[0], curr_eid_contr_side[1])][neuron][trial])\n",
        "\n",
        "                assert(len(curr_dot_prod[-1]) == len(time_axis))\n",
        "\n",
        "            curr_dot_prod = np.array(curr_dot_prod)\n",
        "\n",
        "            assert(curr_dot_prod.shape == (len(curr_coeffs), len(time_axis)))\n",
        "\n",
        "            curr_dot_prod_res = np.sum(curr_dot_prod, axis=0) / curr_max_w_len\n",
        "\n",
        "            assert(len(curr_dot_prod_res) == len(time_axis))\n",
        "\n",
        "            if curr_repr not in proj_all.keys():\n",
        "                proj_all[curr_repr] = {}\n",
        "\n",
        "            if curr_eid_contr_side not in proj_all[curr_repr].keys():\n",
        "                proj_all[curr_repr][curr_eid_contr_side] = {}\n",
        "\n",
        "            proj_all[curr_repr][curr_eid_contr_side][trial] = curr_dot_prod_res\n"
      ],
      "metadata": {
        "id": "CXLcrrxrNtuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking for the significant difference in the projections"
      ],
      "metadata": {
        "id": "XYRtuwI1OB60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perm_stat(x, y, axis):\n",
        "    return np.mean(x, axis=axis) - np.mean(y, axis=axis)\n"
      ],
      "metadata": {
        "id": "2iXw2bMXnq8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind2sess   = {'choice' : {}, 'error' : {}}\n",
        "proj_diff  = {'choice' : {}, 'error' : {}}\n",
        "pvals_all  = {'choice' : [], 'error' : []}\n",
        "pvals_corr = {}\n",
        "\n",
        "for curr_repr in proj_all.keys():\n",
        "\n",
        "    for curr_ind, curr_eid_contr_side in enumerate(sorted(list(proj_all[curr_repr].keys()))):\n",
        "\n",
        "        ind2sess[curr_repr][curr_ind] = curr_eid_contr_side\n",
        "\n",
        "        curr_ind_t_max = t_max_coeffs[(curr_eid_contr_side[0], curr_eid_contr_side[1])][curr_repr]\n",
        "\n",
        "        curr_tmax_pes  = []\n",
        "        curr_tmax_npes = []\n",
        "\n",
        "        for trial in sorted(list(matched_trials[curr_eid_contr_side][curr_repr]['pes'])):\n",
        "            curr_tmax_pes.append(proj_all[curr_repr][curr_eid_contr_side][trial][curr_ind_t_max])\n",
        "\n",
        "        for trial in sorted(list(matched_trials[curr_eid_contr_side][curr_repr]['npes'])):\n",
        "            curr_tmax_npes.append(proj_all[curr_repr][curr_eid_contr_side][trial][curr_ind_t_max])\n",
        "\n",
        "        pvals_all[curr_repr].append(permutation_test((curr_tmax_pes, curr_tmax_npes), perm_stat, vectorized=True, alternative='two-sided', n_resamples=1e6).pvalue)\n",
        "\n",
        "        proj_diff[curr_repr][curr_eid_contr_side] = np.mean(curr_tmax_pes) - np.mean(curr_tmax_npes)\n",
        "\n",
        "    _, curr_pval_corrected, _, _ = multipletests(pvals_all[curr_repr], alpha=0.05, method='fdr_bh')\n",
        "\n",
        "    pvals_corr[curr_repr] = curr_pval_corrected\n"
      ],
      "metadata": {
        "id": "rKKLskX5OIbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_all        = {'choice' : [], 'error' : []}\n",
        "pvals_corr_sess = {'choice' : {}, 'error' : {}}\n",
        "\n",
        "for curr_repr in sorted(list(proj_diff.keys())):\n",
        "    for curr_eid_contr_side in sorted(list(proj_diff[curr_repr].keys())):\n",
        "        diff_all[curr_repr].append(proj_diff[curr_repr][curr_eid_contr_side])\n",
        "\n",
        "for curr_repr in sorted(list(ind2sess.keys())):\n",
        "    for curr_ind in sorted(list(ind2sess[curr_repr].keys())):\n",
        "        pvals_corr_sess[curr_repr][ind2sess[curr_repr][curr_ind]] = pvals_corr[curr_repr][curr_ind]\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "sns.histplot(diff_all['error'], bins='auto', ax=axs[0, 0], color='#78B8E6')\n",
        "axs[0, 0].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "axs[0, 0].set(xlabel='Difference in projection for \"error\"', ylabel='Number of triplets')\n",
        "axs[0, 0].set_xlim(-5.0, 5.0)\n",
        "\n",
        "sns.histplot(pvals_all['error'], binwidth=0.05, binrange=(0.0, 1.0), ax=axs[0, 1], color='#78B8E6')\n",
        "axs[0, 1].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "axs[0, 1].set(xlabel='p-values for \"error\"', ylabel='Number of triplets')\n",
        "\n",
        "sns.histplot(diff_all['choice'], bins='auto', ax=axs[1, 0], color='#78B8E6')\n",
        "axs[1, 0].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "axs[1, 0].set(xlabel='Difference in projection for \"choice\"', ylabel='Number of triplets')\n",
        "axs[1, 0].set_xlim(-5.0, 5.0)\n",
        "\n",
        "sns.histplot(pvals_all['choice'], binwidth=0.05, binrange=(0.0, 1.0), ax=axs[1, 1], color='#78B8E6')\n",
        "axs[1, 1].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "axs[1, 1].set(xlabel='p-values for \"choice\"', ylabel='Number of triplets')\n",
        "\n",
        "fig.subplots_adjust(hspace=0.35)\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', bbox_inches='tight', dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "24Z-D2NmmF-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_error  = sorted(pvals_corr_sess['error'].keys(),  key=lambda k : pvals_corr_sess['error'][k])\n",
        "sorted_choice = sorted(pvals_corr_sess['choice'].keys(), key=lambda k : pvals_corr_sess['choice'][k])\n",
        "\n",
        "curr_eids_error  = list(set([str(sess_contr_side[0]) for sess_contr_side in sorted_error]))\n",
        "curr_eids_choice = list(set([str(sess_contr_side[0]) for sess_contr_side in sorted_choice]))\n",
        "\n",
        "curr_abbr_error  = [EID[ : n_char_eid] for EID in curr_eids_error]\n",
        "curr_abbr_choice = [EID[ : n_char_eid] for EID in curr_eids_choice]\n",
        "\n",
        "assert(len(curr_abbr_error)  == len(set(curr_abbr_error)))\n",
        "assert(len(curr_abbr_choice) == len(set(curr_abbr_choice)))\n"
      ],
      "metadata": {
        "id": "JjGABCR1HqJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_table_error = pd.DataFrame({\n",
        "    'Session'      : [str(sess_contr_side[0])[ : n_char_eid] for sess_contr_side in sorted_error],\n",
        "    'Contrast'     : [sess_contr_side[1] for sess_contr_side in sorted_error],\n",
        "    'Side'         : [sess_contr_side[2] for sess_contr_side in sorted_error],\n",
        "    'Corr. p-val.' : [np.round(pvals_corr_sess['error'][sess_contr_side], 4) for sess_contr_side in sorted_error],\n",
        "    'Proj. diff.'  : [np.round(proj_diff['error'][sess_contr_side],  4)      for sess_contr_side in sorted_error]})\n",
        "\n",
        "plt.table(cellText=df_table_error.values, colLabels=df_table_error.columns, cellLoc='center', loc='center')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', bbox_inches='tight', dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ydejfs_mGh9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_table_choice = pd.DataFrame({\n",
        "    'Session'      : [str(sess_contr_side[0])[ : n_char_eid] for sess_contr_side in sorted_choice],\n",
        "    'Contrast'     : [sess_contr_side[1] for sess_contr_side in sorted_choice],\n",
        "    'Side'         : [sess_contr_side[2] for sess_contr_side in sorted_choice],\n",
        "    'Corr. p-val.' : [np.round(pvals_corr_sess['choice'][sess_contr_side], 4) for sess_contr_side in sorted_choice],\n",
        "    'Proj. diff.'  : [np.round(proj_diff['choice'][sess_contr_side],  4)      for sess_contr_side in sorted_choice]})\n",
        "\n",
        "plt.table(cellText=df_table_choice.values, colLabels=df_table_choice.columns, cellLoc='center', loc='center')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', bbox_inches='tight', dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "07WXGiNmY2An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method figure"
      ],
      "metadata": {
        "id": "zUnERBqaUvyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_error  = []\n",
        "relevant_choice = []\n",
        "\n",
        "for curr_eid_contr_side in sorted(list(pvals_corr_sess['error'].keys())):\n",
        "    if pvals_corr_sess['error'][curr_eid_contr_side] < signif_lvl:\n",
        "        relevant_error.append(curr_eid_contr_side)\n",
        "\n",
        "for curr_eid_contr_side in sorted(list(pvals_corr_sess['choice'].keys())):\n",
        "    if pvals_corr_sess['choice'][curr_eid_contr_side] < signif_lvl:\n",
        "        relevant_choice.append(curr_eid_contr_side)\n",
        "\n",
        "assert(len(relevant_error)  == 1)\n",
        "assert(len(relevant_choice) == 1)\n",
        "\n",
        "exampl_error  = relevant_error[0]\n",
        "exampl_choice = relevant_choice[0]\n",
        "\n",
        "print('Only triplet found for error:',  exampl_error)\n",
        "print('Only triplet found for choice:', exampl_choice)\n"
      ],
      "metadata": {
        "id": "jJxyh0E4tRxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info_ex_error = one.get_details('07dc4b76-5b93-4a03-82a0-b3d9cc73f412')\n",
        "\n",
        "print('Error example:')\n",
        "print('EID:', '07dc4b76-5b93-4a03-82a0-b3d9cc73f412')\n",
        "print('Contrast:', 1.0)\n",
        "print('Stimulus side:', 'right')\n",
        "print('Lab:', info_ex_error['lab'])\n",
        "print('Animal:', info_ex_error['subject'])\n",
        "print('Starting time:', info_ex_error['start_time'])\n",
        "\n",
        "info_ex_choice = one.get_details('1b9e349e-93f2-41cc-a4b5-b212d7ddc8df')\n",
        "\n",
        "print()\n",
        "print('Choice example:')\n",
        "print('EID:', '1b9e349e-93f2-41cc-a4b5-b212d7ddc8df')\n",
        "print('Contrast:', 1.0)\n",
        "print('Stimulus side:', 'left')\n",
        "print('Lab:', info_ex_choice['lab'])\n",
        "print('Animal:', info_ex_choice['subject'])\n",
        "print('Starting time:', info_ex_choice['start_time'])\n"
      ],
      "metadata": {
        "id": "USzmLDjpCZC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_rts_plot_error  = [trials_all[exampl_error[0]][exampl_error[1]][trial][0] for trial in sorted(list(trials_all[exampl_error[0]][exampl_error[1]].keys()))]\n",
        "time_inds_plot_error = (int(np.argmin(np.abs(time_axis - (0.0 + time_eps))).astype(int)), int(np.argmin(np.abs(time_axis - np.percentile(curr_rts_plot_error, time_perc_plot))).astype(int)) + 1)\n"
      ],
      "metadata": {
        "id": "z_Jp1i6A9Anh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_rts_plot_choice  = [trials_all[exampl_choice[0]][exampl_choice[1]][trial][0] for trial in sorted(list(trials_all[exampl_choice[0]][exampl_choice[1]].keys()))]\n",
        "time_inds_plot_choice = (int(np.argmin(np.abs(time_axis - (0.0 + time_eps))).astype(int)), int(np.argmin(np.abs(time_axis - np.percentile(curr_rts_plot_choice, time_perc_plot))).astype(int)) + 1)\n"
      ],
      "metadata": {
        "id": "SmKDj7pqbUrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
        "\n",
        "\n",
        "\n",
        "curr_proj_pes  = []\n",
        "curr_proj_npes = []\n",
        "\n",
        "for trial in matched_trials[exampl_error]['error']['pes']:\n",
        "    curr_proj_pes.append(proj_all['error'][exampl_error][trial][time_inds_plot_error[0] : time_inds_plot_error[1]])\n",
        "\n",
        "for trial in matched_trials[exampl_error]['error']['npes']:\n",
        "    curr_proj_npes.append(proj_all['error'][exampl_error][trial][time_inds_plot_error[0] : time_inds_plot_error[1]])\n",
        "\n",
        "axs[0, 0].plot(time_axis[time_inds_plot_error[0] : time_inds_plot_error[1]], np.mean(curr_proj_npes, axis=0), color='#FFB84D', label='Post-error non-slow')\n",
        "axs[0, 0].plot(time_axis[time_inds_plot_error[0] : time_inds_plot_error[1]], np.mean(curr_proj_pes,  axis=0), color='#FF6F61', label='Post-error slow')\n",
        "\n",
        "axs[0, 0].arrow(x=time_axis[t_max_coeffs[(exampl_error[0], exampl_error[1])]['error']],\n",
        "                y=1.5 * axs[0, 0].get_ylim()[1],\n",
        "                dx=0,\n",
        "                dy=-0.8,\n",
        "                head_width=8.0,\n",
        "                head_length=0.5,\n",
        "                fc='k',\n",
        "                ec='k',\n",
        "                linewidth=1.5)\n",
        "\n",
        "axs[0, 0].set_xlabel('Time from Go cue (ms)')\n",
        "axs[0, 0].set_ylabel('Average projection onto the \"error\" axis')\n",
        "axs[0, 0].legend()\n",
        "\n",
        "\n",
        "\n",
        "curr_proj_pes_tmax  = []\n",
        "curr_proj_npes_tmax = []\n",
        "\n",
        "for trial in matched_trials[exampl_error]['error']['pes']:\n",
        "    curr_proj_pes_tmax.append(proj_all['error'][exampl_error][trial][t_max_coeffs[(exampl_error[0], exampl_error[1])]['error']])\n",
        "\n",
        "for trial in matched_trials[exampl_error]['error']['npes']:\n",
        "    curr_proj_npes_tmax.append(proj_all['error'][exampl_error][trial][t_max_coeffs[(exampl_error[0], exampl_error[1])]['error']])\n",
        "\n",
        "df_pes_error  = pd.DataFrame({'Projection' : curr_proj_pes_tmax,  'Trial type' : 'Post-error slow'})\n",
        "df_npes_error = pd.DataFrame({'Projection' : curr_proj_npes_tmax, 'Trial type' : 'Post-error non-slow'})\n",
        "df_sum_error  = pd.concat([df_pes_error, df_npes_error], ignore_index=True)\n",
        "\n",
        "sns.histplot(df_sum_error, x='Projection', hue='Trial type', palette={'Post-error non-slow' : '#FFB84D', 'Post-error slow' : '#FF6F61'}, ax=axs[0, 1], kde=True, edgecolor=None, alpha=0.5, shrink=0.85, legend=False)\n",
        "\n",
        "axs[0, 1].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "axs[0, 1].set_xlabel('Representation of the side at $t_{max, error}$')\n",
        "axs[0, 1].set_ylabel('Number of trials')\n",
        "\n",
        "\n",
        "\n",
        "curr_proj_pes  = []\n",
        "curr_proj_npes = []\n",
        "\n",
        "for trial in matched_trials[exampl_choice]['choice']['pes']:\n",
        "    curr_proj_pes.append(proj_all['choice'][exampl_choice][trial][time_inds_plot_choice[0] : time_inds_plot_choice[1]])\n",
        "\n",
        "for trial in matched_trials[exampl_choice]['choice']['npes']:\n",
        "    curr_proj_npes.append(proj_all['choice'][exampl_choice][trial][time_inds_plot_choice[0] : time_inds_plot_choice[1]])\n",
        "\n",
        "axs[1, 0].plot(time_axis[time_inds_plot_choice[0] : time_inds_plot_choice[1]], np.mean(curr_proj_npes, axis=0), color='#90BE6D', label='Post-correct slow')\n",
        "axs[1, 0].plot(time_axis[time_inds_plot_choice[0] : time_inds_plot_choice[1]], np.mean(curr_proj_pes,  axis=0), color='#FF6F61', label='Post-error slow')\n",
        "\n",
        "axs[1, 0].arrow(x=time_axis[t_max_coeffs[(exampl_choice[0], exampl_choice[1])]['choice']],\n",
        "                y=1.8 * axs[1, 0].get_ylim()[1],\n",
        "                dx=0,\n",
        "                dy=-0.5,\n",
        "                head_width=9.0,\n",
        "                head_length=0.35,\n",
        "                fc='k',\n",
        "                ec='k',\n",
        "                linewidth=1.5)\n",
        "\n",
        "axs[1, 0].set_ylim(bottom=-6.0, top=None)\n",
        "axs[1, 0].set_xlabel('Time from Go cue (ms)')\n",
        "axs[1, 0].set_ylabel('Average projection onto the \"choice\" axis')\n",
        "axs[1, 0].legend()\n",
        "\n",
        "\n",
        "\n",
        "curr_proj_pes_tmax  = []\n",
        "curr_proj_npes_tmax = []\n",
        "\n",
        "for trial in matched_trials[exampl_choice]['choice']['pes']:\n",
        "    curr_proj_pes_tmax.append(proj_all['choice'][exampl_choice][trial][t_max_coeffs[(exampl_choice[0], exampl_choice[1])]['choice']])\n",
        "\n",
        "for trial in matched_trials[exampl_choice]['choice']['npes']:\n",
        "    curr_proj_npes_tmax.append(proj_all['choice'][exampl_choice][trial][t_max_coeffs[(exampl_choice[0], exampl_choice[1])]['choice']])\n",
        "\n",
        "df_pes_choice  = pd.DataFrame({'Projection' : curr_proj_pes_tmax,  'Trial type' : 'Post-error slow'})\n",
        "df_npes_choice = pd.DataFrame({'Projection' : curr_proj_npes_tmax, 'Trial type' : 'Post-correct slow'})\n",
        "df_sum_choice  = pd.concat([df_pes_choice, df_npes_choice], ignore_index=True)\n",
        "\n",
        "sns.histplot(df_sum_choice, x='Projection', hue='Trial type', palette={'Post-correct slow' : '#90BE6D', 'Post-error slow' : '#FF6F61'}, ax=axs[1, 1], kde=True, edgecolor=None, alpha=0.5, shrink=0.85, legend=False)\n",
        "\n",
        "axs[1, 1].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "axs[1, 1].set_xlabel('Representation of the side at $t_{max, choice}$')\n",
        "axs[1, 1].set_ylabel('Number of trials')\n",
        "\n",
        "\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "80BgxrD9zaZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regions involved in post-error slowing"
      ],
      "metadata": {
        "id": "DCvbQxlI8oM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs_all = {'error' : [], 'choice' : []}\n",
        "\n",
        "for neuron in sorted(list(w_max_coeffs[(exampl_error[0], exampl_error[1])]['error'].keys())):\n",
        "    coeffs_all['error'].append(np.abs(w_max_coeffs[(exampl_error[0], exampl_error[1])]['error'][neuron]))\n",
        "\n",
        "for neuron in sorted(list(w_max_coeffs[(exampl_choice[0], exampl_choice[1])]['choice'].keys())):\n",
        "    coeffs_all['choice'].append(np.abs(w_max_coeffs[(exampl_choice[0], exampl_choice[1])]['choice'][neuron]))\n",
        "\n",
        "coeff_thres_error  = np.percentile(coeffs_all['error'],  perc_coeff)\n",
        "coeff_thres_choice = np.percentile(coeffs_all['choice'], perc_coeff)\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "\n",
        "sns.histplot(coeffs_all['error'], ax=ax[0], bins='doane', color='#5D7FA3')\n",
        "ax[0].vlines(coeff_thres_error, 0, ax[0].get_ylim()[1], linestyle='--', color='#FF80AB', label=str(perc_coeff) + 'th percentile')\n",
        "\n",
        "ax[0].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "ax[0].set_xlabel('Absolute value of \"error\" coefficients')\n",
        "ax[0].set_ylabel('Number of neurons')\n",
        "\n",
        "\n",
        "sns.histplot(coeffs_all['choice'], ax=ax[1], bins='doane', color='#5D7FA3')\n",
        "ax[1].vlines(coeff_thres_choice, 0, ax[1].get_ylim()[1], linestyle='--', color='#FF80AB', label=str(perc_coeff) + 'th percentile')\n",
        "\n",
        "ax[1].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "ax[1].set_xlabel('Absolute value of \"choice\" coefficients')\n",
        "ax[1].set_ylabel('Number of neurons')\n",
        "\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S1fJ67Q2fRIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_swans_error = []\n",
        "\n",
        "for neuron in sorted(list(w_max_coeffs[(exampl_error[0], exampl_error[1])]['error'].keys())):\n",
        "\n",
        "    curr_coeff = np.abs(w_max_coeffs[(exampl_error[0], exampl_error[1])]['error'][neuron])\n",
        "\n",
        "    if ((curr_coeff > coeff_thres_error) and (neuron in neuron_region.keys())):\n",
        "\n",
        "        curr_region = neuron_region[neuron]\n",
        "\n",
        "        if curr_region not in reg_swans_error:\n",
        "\n",
        "            reg_swans_error.append(curr_region)\n",
        "\n",
        "\n",
        "reg_swans_choice = []\n",
        "\n",
        "for neuron in sorted(list(w_max_coeffs[(exampl_choice[0], exampl_choice[1])]['choice'].keys())):\n",
        "\n",
        "    curr_coeff = np.abs(w_max_coeffs[(exampl_choice[0], exampl_choice[1])]['choice'][neuron])\n",
        "\n",
        "    if ((curr_coeff > coeff_thres_choice) and (neuron in neuron_region.keys())):\n",
        "\n",
        "        curr_region = neuron_region[neuron]\n",
        "\n",
        "        if curr_region not in reg_swans_choice:\n",
        "\n",
        "            reg_swans_choice.append(curr_region)\n",
        "\n",
        "reg_swans_all = list(set(reg_swans_error) | set(reg_swans_choice))\n",
        "val_swans_all = []\n",
        "\n",
        "for region in reg_swans_all:\n",
        "\n",
        "    if (region in reg_swans_error) and (region in reg_swans_choice):\n",
        "        val_swans_all.append(2.0)\n",
        "    elif (region in reg_swans_error) and (region not in reg_swans_choice):\n",
        "        val_swans_all.append(0.0)\n",
        "    elif (region not in reg_swans_error) and (region in reg_swans_choice):\n",
        "        val_swans_all.append(1.0)\n",
        "\n",
        "val_swans_all = np.array(val_swans_all)\n"
      ],
      "metadata": {
        "id": "PVLNFcSEaRro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors  import ListedColormap\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "swans_leg_vals = [0.0, 1.0, 2.0]\n",
        "swans_leg_repr = ['Error', 'Choice', 'Both']\n",
        "swans_leg_cols = ['#C3B1E1', '#FFD8B8', '#A4D4F4']\n",
        "custom_cmap    = ListedColormap(swans_leg_cols)\n",
        "\n",
        "legend_elements = [Patch(facecolor=swans_leg_cols[i], label=f'{swans_leg_repr[i]}') for i in range(len(swans_leg_vals))]\n",
        "\n",
        "fig, ax_swans = plt.subplots(1, 1, figsize=(12, 9))\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter('ignore', category=RuntimeWarning)\n",
        "\n",
        "    plot_swanson_vector(reg_swans_all,\n",
        "                        val_swans_all,\n",
        "                        ax=ax_swans,\n",
        "                        cmap=custom_cmap,\n",
        "                        vmin=np.min(swans_leg_vals),\n",
        "                        vmax=np.max(swans_leg_vals),\n",
        "                        empty_color='whitesmoke')\n",
        "\n",
        "ax_swans.set_axis_off()\n",
        "\n",
        "ax_swans.legend(handles=legend_elements, loc='lower left',  bbox_to_anchor=(0.0, 0.9), title='Differently representing', title_fontsize=14)\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WsiCMps8lJ-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ytkfX3GR040g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NCI19nL_vF-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p9p0yFDxvGBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}