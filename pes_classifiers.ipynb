{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1iQMjmLeNeTVpb4D3bPpJ-6ojwMWsKBK9",
      "authorship_tag": "ABX9TyPDI6dSyvxLAEBCDROmg3rL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gergogomori/brain_wide_pes/blob/main/pes_classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C313-ERcS-VM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import uuid\n",
        "\n",
        "import pandas  as pd\n",
        "import seaborn as sns\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "from sklearn.linear_model    import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics         import f1_score\n",
        "\n",
        "from warnings           import filterwarnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "filterwarnings('ignore', category=RuntimeWarning)\n",
        "filterwarnings('ignore', category=ConvergenceWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "\n",
        "mpl.rcParams.update({\n",
        "    'axes.labelsize'  : 15,\n",
        "    'xtick.labelsize' : 14,\n",
        "    'ytick.labelsize' : 14,\n",
        "    'legend.fontsize' : 14})\n"
      ],
      "metadata": {
        "id": "c_HKDslUTbRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('*** Update the folder path here to match your directory structure ***', 'rb') as f:\n",
        "    trials_all = pickle.load(f)\n",
        "\n",
        "with open('*** Update the folder path here to match your directory structure ***', 'rb') as f:\n",
        "    matched_trials = pickle.load(f)\n",
        "\n",
        "with open('*** Update the folder path here to match your directory structure ***', 'rb') as f:\n",
        "    fr_z = pickle.load(f)\n",
        "\n",
        "with open('*** Update the folder path here to match your directory structure ***', 'rb') as f:\n",
        "    neuron_region = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "WIw3e0SWWPj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matched_trials_mod = {}\n",
        "\n",
        "for curr_eid_contr_side in sorted(list(matched_trials.keys())):\n",
        "\n",
        "    matched_trials_mod[curr_eid_contr_side] = {}\n",
        "\n",
        "    for curr_repr in sorted(list(matched_trials[curr_eid_contr_side].keys())):\n",
        "\n",
        "        if curr_repr == 'error':\n",
        "            matched_trials_mod[curr_eid_contr_side]['slowing'] = matched_trials[curr_eid_contr_side]['error']\n",
        "\n",
        "        elif curr_repr == 'choice':\n",
        "            matched_trials_mod[curr_eid_contr_side]['error'] = matched_trials[curr_eid_contr_side]['choice']\n"
      ],
      "metadata": {
        "id": "owhKAfZ-TLpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTED PARAMETERS\n",
        "\n",
        "time_eps        = 5.0 # ms\n",
        "time_end_perc   = 5\n",
        "\n",
        "t_lims     = (-350.0, 350.0) # ms\n",
        "sampl_rate = 10.0 # ms\n",
        "time_axis  = np.arange(t_lims[0] + sampl_rate / 2, t_lims[1] - sampl_rate / 2 + 1, sampl_rate)\n",
        "\n",
        "print(time_axis)\n"
      ],
      "metadata": {
        "id": "i4DZZB6UWPmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW PARAMETERS\n",
        "\n",
        "regul_C    = [pow(10.0, C) for C in list(range(-2, 3))]\n",
        "n_models   = 10\n",
        "r_test     = 0.2\n",
        "r_dev      = 0.3\n",
        "perf_thres = 0.7\n",
        "\n",
        "print(f'Regularization parameters: {regul_C}')\n"
      ],
      "metadata": {
        "id": "LkxlN8brWPpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the classifiers"
      ],
      "metadata": {
        "id": "laFMZ60ad7lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perf_all = {'slowing' : {}, 'error' : {}}\n",
        "\n",
        "for ind_curr_eid_contr_side, curr_eid_contr_side in enumerate(sorted(list(matched_trials_mod.keys()))):\n",
        "\n",
        "    print('Done with', np.around(ind_curr_eid_contr_side / len(matched_trials_mod.keys()) * 100, 1), '% of the data.')\n",
        "\n",
        "    curr_rts = []\n",
        "\n",
        "    for trial in sorted(list(trials_all[curr_eid_contr_side[0]][curr_eid_contr_side[1]].keys())):\n",
        "        curr_rts.append(trials_all[curr_eid_contr_side[0]][curr_eid_contr_side[1]][trial][0])\n",
        "\n",
        "    curr_time_inds = (int(np.argmin(np.abs(time_axis - (0.0 + time_eps))).astype(int)), int(np.argmin(np.abs(time_axis - np.percentile(curr_rts, time_end_perc))).astype(int)) + 1)\n",
        "\n",
        "    for curr_repr in sorted(list(matched_trials_mod[curr_eid_contr_side].keys())):\n",
        "\n",
        "        perf_all[curr_repr][curr_eid_contr_side] = {}\n",
        "\n",
        "        for neuron in sorted(list(fr_z[(curr_eid_contr_side[0], curr_eid_contr_side[1])])):\n",
        "\n",
        "            perf_all[curr_repr][curr_eid_contr_side][neuron] = {}\n",
        "\n",
        "            curr_data = []\n",
        "            curr_labl = []\n",
        "\n",
        "            for trial in matched_trials_mod[curr_eid_contr_side][curr_repr]['pes']:\n",
        "                curr_data.append(fr_z[(curr_eid_contr_side[0], curr_eid_contr_side[1])][neuron][trial][curr_time_inds[0] : curr_time_inds[1]])\n",
        "                curr_labl.append(1)\n",
        "\n",
        "            for trial in matched_trials_mod[curr_eid_contr_side][curr_repr]['npes']:\n",
        "                curr_data.append(fr_z[(curr_eid_contr_side[0], curr_eid_contr_side[1])][neuron][trial][curr_time_inds[0] : curr_time_inds[1]])\n",
        "                curr_labl.append(0)\n",
        "\n",
        "            curr_data = np.array(curr_data)\n",
        "            curr_labl = np.array(curr_labl)\n",
        "\n",
        "            assert(len(curr_data) == len(curr_labl))\n",
        "\n",
        "            curr_res = []\n",
        "\n",
        "            for ind_mod in range(n_models):\n",
        "\n",
        "                X_not_test, X_test, y_not_test, y_test = train_test_split(curr_data,  curr_labl,  test_size=r_test, stratify=curr_labl)\n",
        "                X_train, X_dev, y_train, y_dev         = train_test_split(X_not_test, y_not_test, test_size=r_dev,  stratify=y_not_test)\n",
        "\n",
        "                res_dev = {}\n",
        "\n",
        "                for curr_C in regul_C:\n",
        "\n",
        "                    curr_mod = LogisticRegression(max_iter=100, penalty='l2', C=curr_C, fit_intercept=True)\n",
        "                    curr_mod.fit(X_train, y_train)\n",
        "\n",
        "                    res_dev[curr_C] = f1_score(y_dev, curr_mod.predict(X_dev))\n",
        "\n",
        "                best_C   = max(res_dev, key=res_dev.get)\n",
        "                best_mod = LogisticRegression(max_iter=100, penalty='l2', C=best_C, fit_intercept=True)\n",
        "\n",
        "                best_mod.fit(np.concatenate((X_train, X_dev)), np.concatenate((y_train, y_dev)))\n",
        "\n",
        "                curr_res.append(f1_score(y_test, best_mod.predict(X_test)))\n",
        "\n",
        "            perf_all[curr_repr][curr_eid_contr_side][neuron] = curr_res\n",
        "\n",
        "with open('*** Update the folder path here to match your directory structure ***', 'wb') as f:\n",
        "    pickle.dump(perf_all, f, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "gz7I2-wudjk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting one neuron for each trial condition"
      ],
      "metadata": {
        "id": "-31OL6e-ClAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess_cond = {'error' : {}, 'both' : {}}\n",
        "\n",
        "all_sess_contr_side = sorted(list(set(perf_all['slowing'].keys()) | set(perf_all['error'].keys())))\n",
        "\n",
        "for curr_eid_contr_side in all_sess_contr_side:\n",
        "\n",
        "    if curr_eid_contr_side in perf_all['slowing'].keys():\n",
        "\n",
        "        assert(curr_eid_contr_side in perf_all['error'].keys())\n",
        "\n",
        "    if (curr_eid_contr_side in perf_all['slowing'].keys()) and (curr_eid_contr_side in perf_all['error'].keys()):\n",
        "\n",
        "        if curr_eid_contr_side[0] not in sess_cond['both'].keys():\n",
        "            sess_cond['both'][curr_eid_contr_side[0]] = [curr_eid_contr_side]\n",
        "        else:\n",
        "            sess_cond['both'][curr_eid_contr_side[0]].append(curr_eid_contr_side)\n",
        "\n",
        "\n",
        "for curr_eid_contr_side in all_sess_contr_side:\n",
        "\n",
        "    if curr_eid_contr_side[0] not in sess_cond['both'].keys():\n",
        "\n",
        "        assert(not((curr_eid_contr_side in perf_all['slowing'].keys()) and (curr_eid_contr_side in perf_all['error'].keys())))\n",
        "\n",
        "        if curr_eid_contr_side in perf_all['error'].keys():\n",
        "\n",
        "            assert(curr_eid_contr_side not in perf_all['slowing'].keys())\n",
        "\n",
        "            if curr_eid_contr_side[0] not in sess_cond['error'].keys():\n",
        "                sess_cond['error'][curr_eid_contr_side[0]] = [curr_eid_contr_side]\n",
        "            else:\n",
        "                sess_cond['error'][curr_eid_contr_side[0]].append(curr_eid_contr_side)\n"
      ],
      "metadata": {
        "id": "pNqoOadOpy1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perf_neurons = {'slowing' : {}, 'error' : {}}\n",
        "\n",
        "\n",
        "for EID in sess_cond['error'].keys():\n",
        "\n",
        "    if len(sess_cond['error'][EID]) == 1:\n",
        "\n",
        "        for neuron in perf_all['error'][sess_cond['error'][EID][0]].keys():\n",
        "            perf_neurons['error'][neuron] = np.mean(perf_all['error'][sess_cond['error'][EID][0]][neuron])\n",
        "\n",
        "    else:\n",
        "\n",
        "        curr_neurons = {}\n",
        "\n",
        "        for neuron in perf_all['error'][sess_cond['error'][EID][0]].keys():\n",
        "            curr_neurons[neuron] = np.mean(perf_all['error'][sess_cond['error'][EID][0]][neuron])\n",
        "\n",
        "        for curr_eid_contr_side in sess_cond['error'][EID]:\n",
        "\n",
        "            assert(len(set(curr_neurons.keys()) & set(perf_all['error'][curr_eid_contr_side].keys())) > 0)\n",
        "\n",
        "            for neuron in sorted(list(perf_all['error'][curr_eid_contr_side].keys())):\n",
        "\n",
        "                if neuron in curr_neurons.keys():\n",
        "\n",
        "                    if curr_neurons[neuron] < np.mean(perf_all['error'][curr_eid_contr_side][neuron]):\n",
        "\n",
        "                        curr_neurons[neuron] = np.mean(perf_all['error'][curr_eid_contr_side][neuron])\n",
        "\n",
        "                else:\n",
        "                    curr_neurons[neuron] = np.mean(perf_all['error'][curr_eid_contr_side][neuron])\n",
        "\n",
        "        perf_neurons['error'].update(curr_neurons)\n"
      ],
      "metadata": {
        "id": "jf1ae9xkpy6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for EID in sess_cond['both'].keys():\n",
        "\n",
        "    if len(sess_cond['both'][EID]) == 1:\n",
        "\n",
        "        curr_neurons = sorted(list(perf_all['slowing'][sess_cond['both'][EID][0]].keys()))\n",
        "\n",
        "        assert(curr_neurons == sorted(list(perf_all['error'][sess_cond['both'][EID][0]].keys())))\n",
        "\n",
        "        for neuron in curr_neurons:\n",
        "\n",
        "            perf_neurons['slowing'][neuron] = np.mean(perf_all['slowing'][sess_cond['both'][EID][0]][neuron])\n",
        "            perf_neurons['error'][neuron]   = np.mean(perf_all['error'][sess_cond['both'][EID][0]][neuron])\n",
        "\n",
        "    else:\n",
        "\n",
        "        assert(len(sess_cond['both'][EID]) == 2)\n",
        "\n",
        "        curr_neurons_slowing = set()\n",
        "        curr_neurons_error   = set()\n",
        "\n",
        "        for curr_eid_contr_side in sess_cond['both'][EID]:\n",
        "            curr_neurons_slowing |= set(perf_all['slowing'][curr_eid_contr_side].keys())\n",
        "            curr_neurons_error   |= set(perf_all['error'][curr_eid_contr_side].keys())\n",
        "\n",
        "        assert(curr_neurons_slowing == curr_neurons_error)\n",
        "\n",
        "        for neuron in sorted(list(curr_neurons_slowing)):\n",
        "\n",
        "            curr_res = {}\n",
        "\n",
        "            for curr_eid_contr_side in sess_cond['both'][EID]:\n",
        "\n",
        "                if neuron in perf_all['slowing'][curr_eid_contr_side]:\n",
        "\n",
        "                    assert(neuron in perf_all['error'][curr_eid_contr_side])\n",
        "\n",
        "                    curr_res[curr_eid_contr_side] = np.max([np.mean(perf_all['slowing'][curr_eid_contr_side][neuron]), np.mean(perf_all['error'][curr_eid_contr_side][neuron])])\n",
        "\n",
        "            assert(len(curr_res.keys()) == 2)\n",
        "\n",
        "            best_perf_sess = max(curr_res, key=curr_res.get)\n",
        "\n",
        "            perf_neurons['slowing'][neuron] = np.mean(perf_all['slowing'][best_perf_sess][neuron])\n",
        "            perf_neurons['error'][neuron]   = np.mean(perf_all['error'][best_perf_sess][neuron])\n",
        "\n",
        "assert((set(perf_neurons['slowing'].keys()) & set(perf_neurons['error'].keys())) == set(perf_neurons['slowing'].keys()))\n"
      ],
      "metadata": {
        "id": "G-Zzn2E7py8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance distribution"
      ],
      "metadata": {
        "id": "mQZ3xoG7eCbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perf_pooled = {'slowing' : [], 'error' : []}\n",
        "\n",
        "for curr_repr in ['slowing', 'error']:\n",
        "    for neuron in sorted(list(perf_neurons[curr_repr].keys())):\n",
        "        perf_pooled[curr_repr].append(perf_neurons[curr_repr][neuron])\n",
        "\n",
        "\n",
        "_, ax = plt.subplots(1, 2, figsize=(10, 4), sharex=True, sharey=True)\n",
        "\n",
        "sns.histplot(perf_pooled['slowing'], ax=ax[0], binwidth=0.05, binrange=(0.0, 1.0), color='#5D7FA3')\n",
        "\n",
        "ax[0].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "ax[0].set_xlabel('Performance for predicting \\n\"slowing\"')\n",
        "ax[0].set_ylabel('Number of neurons')\n",
        "\n",
        "\n",
        "sns.histplot(perf_pooled['error'], ax=ax[1], binwidth=0.05, binrange=(0.0, 1.0), color='#5D7FA3')\n",
        "\n",
        "curr_plot_y_max = ax[1].get_ylim()[1]\n",
        "ax[1].vlines(perf_thres, 0, curr_plot_y_max, linestyle='--', color='#FF80AB')\n",
        "ax[0].vlines(perf_thres, 0, curr_plot_y_max, linestyle='--', color='#FF80AB')\n",
        "\n",
        "ax[1].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "ax[1].set_xlabel('Performance for predicting \\n(the previous) error')\n",
        "ax[1].set_ylabel('Number of neurons')\n",
        "ax[1].tick_params(axis='y', labelleft=True)\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w6RFjdTvJMm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Location of neurons with high performance"
      ],
      "metadata": {
        "id": "pjSQMQUOeK8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regions_all = {}\n",
        "\n",
        "all_neurons = sorted(list(set(perf_neurons['slowing'].keys()) | set(perf_neurons['error'].keys())))\n",
        "\n",
        "for neuron in all_neurons:\n",
        "\n",
        "    if neuron in neuron_region.keys():\n",
        "\n",
        "        curr_region = neuron_region[neuron]\n",
        "\n",
        "        if curr_region not in regions_all.keys():\n",
        "            regions_all[curr_region] = {'slowing' : 0, 'error' : 0, 'both' : 0, 'all' : 1}\n",
        "        else:\n",
        "            regions_all[curr_region]['all'] += 1\n",
        "\n",
        "        if ((neuron in perf_neurons['slowing'].keys()) and (neuron in perf_neurons['error'].keys())):\n",
        "\n",
        "            if ((perf_neurons['slowing'][neuron] > perf_thres) and (perf_neurons['error'][neuron] > perf_thres)):\n",
        "                regions_all[curr_region]['both'] += 1\n",
        "\n",
        "            else:\n",
        "                if perf_neurons['slowing'][neuron] > perf_thres:\n",
        "                    regions_all[curr_region]['slowing'] += 1\n",
        "\n",
        "                if perf_neurons['error'][neuron] > perf_thres:\n",
        "                    regions_all[curr_region]['error'] += 1\n",
        "\n",
        "        elif neuron in perf_neurons['error'].keys():\n",
        "\n",
        "            assert(not(neuron in perf_neurons['slowing'].keys()))\n",
        "\n",
        "            if perf_neurons['error'][neuron] > perf_thres:\n",
        "                regions_all[curr_region]['error'] += 1\n",
        "\n",
        "\n",
        "not_involved_regions = []\n",
        "\n",
        "for region in sorted(list(regions_all.keys())):\n",
        "\n",
        "    if (regions_all[region]['slowing'] == 0 and regions_all[region]['error'] == 0 and regions_all[region]['both'] == 0) or (regions_all[region]['all'] < 30):\n",
        "        not_involved_regions.append(region)\n",
        "\n",
        "for region in not_involved_regions:\n",
        "    del regions_all[region]\n",
        "\n",
        "\n",
        "sort_plot_both    = []\n",
        "sort_plot_slowing = []\n",
        "sort_plot_error   = []\n",
        "\n",
        "ratios_all = {}\n",
        "\n",
        "for region in sorted(list(regions_all.keys())):\n",
        "\n",
        "    ratios_all[region] = {'slowing' : regions_all[region]['slowing']  / regions_all[region]['all'],\n",
        "                          'error'   : regions_all[region]['error']    / regions_all[region]['all'],\n",
        "                          'both'    : regions_all[region]['both']     / regions_all[region]['all'],\n",
        "                          'remain'  : (regions_all[region]['all'] - regions_all[region]['slowing'] - regions_all[region]['error'] - regions_all[region]['both']) / regions_all[region]['all']}\n",
        "\n",
        "    assert(ratios_all[region]['slowing'] <= 1.0)\n",
        "    assert(ratios_all[region]['error']   <= 1.0)\n",
        "    assert(ratios_all[region]['both']    <= 1.0)\n",
        "    assert(ratios_all[region]['remain']  <= 1.0)\n",
        "\n",
        "    if regions_all[region]['both'] > 0:\n",
        "        sort_plot_both.append(region)\n",
        "    else:\n",
        "        if regions_all[region]['slowing'] > 0:\n",
        "            assert(ratios_all[region]['both'] == 0.0)\n",
        "            sort_plot_slowing.append(region)\n",
        "        else:\n",
        "            assert(ratios_all[region]['both']    == 0.0)\n",
        "            assert(ratios_all[region]['slowing'] == 0.0)\n",
        "            assert(ratios_all[region]['error']    > 0.0)\n",
        "            sort_plot_error.append(region)\n",
        "\n",
        "\n",
        "sort_plot_both    = sorted(sort_plot_both,    key=lambda k : ratios_all[k]['both'])\n",
        "sort_plot_slowing = sorted(sort_plot_slowing, key=lambda k : ratios_all[k]['slowing'])\n",
        "sort_plot_error   = sorted(sort_plot_error,   key=lambda k : ratios_all[k]['error'])\n",
        "\n",
        "sort_plot_all = sort_plot_error + sort_plot_slowing + sort_plot_both\n",
        "\n",
        "assert(len(set(sort_plot_all)) == len(sort_plot_all))\n",
        "assert(len(sort_plot_all)      == len(ratios_all.keys()))\n"
      ],
      "metadata": {
        "id": "0XKSjbhQaeUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_cols = {'both'    : '#FFB07C',\n",
        "               'slowing' : '#AAF0D1',\n",
        "               'error'   : '#7FB3D5',\n",
        "               'remain'  : '#D3D3D3'}\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(6, 12))\n",
        "\n",
        "for ind_region, region in enumerate(sort_plot_all):\n",
        "    curr_both    = ratios_all[region]['both']\n",
        "    curr_slowing = ratios_all[region]['slowing']\n",
        "    curr_error   = ratios_all[region]['error']\n",
        "    curr_remain  = ratios_all[region]['remain']\n",
        "\n",
        "    ax.barh(ind_region, curr_both,                                               color=region_cols['both'],    label='Both'         if ind_region == 0 else '')\n",
        "    ax.barh(ind_region, curr_slowing,  left=curr_both,                           color=region_cols['slowing'], label='Slowing'      if ind_region == 0 else '')\n",
        "    ax.barh(ind_region, curr_error, left=curr_both + curr_slowing,               color=region_cols['error'],   label='Error'        if ind_region == 0 else '')\n",
        "    ax.barh(ind_region, curr_remain, left=curr_both + curr_slowing + curr_error, color=region_cols['remain'],  label='Not involved' if ind_region == 0 else '')\n",
        "    ax.text(1.01, ind_region, str(regions_all[region]['all']), va='center', ha='left', fontsize=13)\n",
        "\n",
        "ax.set_yticks(range(len(sort_plot_all)))\n",
        "ax.set_yticklabels(sort_plot_all)\n",
        "ax.set_ylim(-0.5, len(sort_plot_all) - 0.5)\n",
        "ax.set_xlim(0.0, 1.15)\n",
        "ax.grid(axis='y', visible=False)\n",
        "\n",
        "ax.set_xlabel('Ratio of analyzed neurons')\n",
        "\n",
        "ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.93))\n",
        "\n",
        "plt.savefig('*** Update the folder path here to match your directory structure ***', format='png', bbox_inches='tight', dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1X7gxepFwC7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-uBDW1GlFvqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1yKr3zx4ebMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZMxcrKSYDL_A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}